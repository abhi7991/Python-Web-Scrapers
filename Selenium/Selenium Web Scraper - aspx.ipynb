{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3d1ee8",
   "metadata": {},
   "source": [
    "# Selenium Web Scraper\n",
    "\n",
    "*To Run - Ensure the chromedriver is installed & Open file in Jupyter Notebook - Kernel -> Restart and Run All*\n",
    "\n",
    "Some websites are built with dynamic Aspx or JavaScript frameworks which Beautiful Soup cannot access. We can use Selenium in this case. This webscraper emulates a Google Chrome web browser controlled through Python code. I used this bot to collect data from various agriculture market across India. These are the steps which the website follows.\n",
    "\n",
    "1. Ping the website using Selenium\n",
    "2. Collect all the States present on the websits\n",
    "3. Iterate through the States and Select required dates which data is present\n",
    "4. Once the required date is selected - Press the submit button\n",
    "5. Collect data from the table\n",
    "6. Go back to the website and collect remaining dates\n",
    "7. Close the browser once the data is collected\n",
    "\n",
    "`time.sleep` is mentioned everywhere to ensure we do not hit the site too fast and to mimic a human user \n",
    "\n",
    "\n",
    "The script uses a `try` and `except` block to capture any error which may occur in the data collection process - ensuring data integrity\n",
    "\n",
    "\n",
    "*For this sample - I have modified the script to go into a single state for a particular date and print a simple dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166bce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Import required packages\n",
    "\n",
    "'''\n",
    "from selenium import webdriver\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import sqlalchemy\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e010b0",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d670154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_time = timezone('Asia/Kolkata')\n",
    "today      = datetime.datetime.now(india_time)\n",
    "days       = datetime.timedelta(1)\n",
    "yesterday = today - days\n",
    "job_start_time = datetime.datetime.now(india_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55fd0c",
   "metadata": {},
   "source": [
    "## Global Functions\n",
    "\n",
    "`input_fun` - This function helps us select the date given the browser, State and date\n",
    "\n",
    "`clean_up` - Once the submit button is pressed using the underlying HTML source we can scrape the table and return a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef912f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fun(driver, st, date):\n",
    "    mon = date.strftime(\"%B\")\n",
    "    year = date.year\n",
    "\n",
    "    st_xpath = '//select[@name=\"ctl00$cphBody$cboState\"]'\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_xpath(st_xpath + \"//option[contains(text(), '\" + st + \"')]\")[0].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    mon_xpath = '//select[@name=\"ctl00$cphBody$cboMonth\"]'\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_xpath(mon_xpath + '//option[contains(text(), \"' + mon + '\")]')[0].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    year_xpath = '//select[@name=\"ctl00$cphBody$cboYear\"]'\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_xpath(year_xpath + '//option[contains(text(), \"' + str(year) + '\")]')[0].click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    return driver\n",
    "\n",
    "def clean_up(chrome,st):\n",
    "\n",
    "        html=chrome.page_source\n",
    "        df1=pd.read_html(html)\n",
    "        dsoup=BeautifulSoup(html,'html.parser')\n",
    "        select = dsoup.find('font', {'color':'Maroon'})\n",
    "        date=select.contents[0].strip()\n",
    "        df=df1[3]\n",
    "        df2 = df.copy()\n",
    "        df2 = df2.iloc[:,0:len(df.columns)-3]\n",
    "        df2.dropna(axis=0,inplace=True)\n",
    "        df=df.drop_duplicates(keep=False)\n",
    "        df = df.query(\"Market != Arrivals\")\n",
    "        new_cols = df.columns.to_list()\n",
    "        new_cols = [x.replace(\" \",'_').replace(\"-\",\"_\") for x in new_cols]\n",
    "        df.columns = new_cols\n",
    "        format_str = '%d/%m/%Y' # The format\n",
    "        datetime_obj = datetime.datetime.strptime(date, format_str)\n",
    "        df=df.rename(columns={'Arrivals':'Arrivals_String'})\n",
    "        df['Arrivals']=np.where(df['Arrivals_String']=='NR',0,df['Arrivals_String'])\n",
    "        df['Relevant_Date']=datetime_obj.strftime(\"%Y-%m-%d\")\n",
    "        df['Runtime'] = pd.to_datetime(today.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        df['Last_Updated'] = ''\n",
    "        df['State']=st\n",
    "        df[['Arrivals','Minimum_Prices', 'Maximum_Prices','Modal_Prices']]=df[['Arrivals','Minimum_Prices', 'Maximum_Prices','Modal_Prices']].apply(pd.to_numeric,errors='coerce')\n",
    "        df['Relevant_Date'] =  pd.to_datetime(df['Relevant_Date'], format='%Y-%m-%d')\n",
    "        df=df[['State','Market', 'Arrivals_String','Arrivals', 'Unit_of_Arrivals', 'Variety', 'Minimum_Prices',\n",
    "               'Maximum_Prices', 'Modal_Prices', 'Unit_of_Price'\n",
    "               , 'Relevant_Date', 'Runtime', 'Last_Updated']]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3758dc",
   "metadata": {},
   "source": [
    "## Main Script\n",
    "\n",
    "*The Script below has the comments by every line to understand what each line does and its functionality*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe5e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Select State--------\n",
      "Andaman and Nicobar\n",
      "Andhra Pradesh\n",
      "Arunachal Pradesh\n",
      "Assam\n",
      "Bihar\n",
      "Chandigarh\n",
      "Chattisgarh\n",
      "Dadra and Nagar Haveli\n",
      "Daman and Diu\n",
      "Goa\n",
      "Gujarat\n",
      "Haryana\n",
      "Himachal Pradesh\n",
      "Jammu and Kashmir\n",
      "Jharkhand\n",
      "Karnataka\n",
      "Kerala\n",
      "Lakshadweep\n",
      "Madhya Pradesh\n",
      "Maharashtra\n",
      "Manipur\n",
      "Meghalaya\n",
      "Mizoram\n",
      "Nagaland\n",
      "NCT of Delhi\n",
      "Odisha\n",
      "Pondicherry\n",
      "Punjab\n",
      "Rajasthan\n",
      "Sikkim\n",
      "Tamil Nadu\n",
      "Telangana\n",
      "Tripura\n",
      "Uttar Pradesh\n",
      "Uttrakhand\n",
      "West Bengal\n",
      "Andhra Pradesh\n",
      "Andhra Pradesh 2022-04-01\n",
      "2022-04-01\n",
      "1\n",
      "            State         Market Arrivals_String  Arrivals Unit_of_Arrivals  \\\n",
      "3  Andhra Pradesh           Alur            0.01      0.01           Tonnes   \n",
      "4  Andhra Pradesh  Banaganapalli               1      1.00           Tonnes   \n",
      "6  Andhra Pradesh        Atmakur            0.01      0.01           Tonnes   \n",
      "8  Andhra Pradesh        Atmakur            0.01      0.01           Tonnes   \n",
      "9  Andhra Pradesh  Banaganapalli               1      1.00           Tonnes   \n",
      "\n",
      "          Variety  Minimum_Prices  Maximum_Prices  Modal_Prices Unit_of_Price  \\\n",
      "3  Jowar ( White)            2400            2500          2450    Rs/Quintal   \n",
      "4  Jowar ( White)            1400            2000          1700    Rs/Quintal   \n",
      "6    Hybrid/Local            1850            1850          1850    Rs/Quintal   \n",
      "8    Sona Mahsuri            1800            1800          1800    Rs/Quintal   \n",
      "9    Sona Mahsuri            1800            2200          2000    Rs/Quintal   \n",
      "\n",
      "  Relevant_Date             Runtime Last_Updated  \n",
      "3    2022-04-01 2024-10-15 00:13:45               \n",
      "4    2022-04-01 2024-10-15 00:13:45               \n",
      "6    2022-04-01 2024-10-15 00:13:45               \n",
      "8    2022-04-01 2024-10-15 00:13:45               \n",
      "9    2022-04-01 2024-10-15 00:13:45               \n",
      "0.703125\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The Script is embedded into a While loop,\n",
    "this ensure that it continues till it reaches\n",
    "a point where all the requirements are achieved \n",
    "and the While loop stops\n",
    "'''\n",
    "main_limit=0\n",
    "while True:\n",
    "    try:\n",
    "        # Monitoring the start time of the script\n",
    "        start = time.process_time()\n",
    "        #Website to scrape\n",
    "        site_url = \"https://agmarknet.gov.in/PriceAndArrivals/CommodityDailyStateWise.aspx\"\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Downloading the Chrome Browser from https://developer.chrome.com/docs/chromedriver/downloads\n",
    "        and placing it in the current working directory\n",
    "        '''\n",
    "        \n",
    "        wd = r'C:\\Personal_Project\\Web_Scraping_Stuff\\Selenium'\n",
    "        driver = webdriver.Chrome(executable_path = wd+\"\\chromedriver.exe\")\n",
    "        driver.get(site_url)\n",
    "        driver.maximize_window()\n",
    "        # Acquiring all states from the HTML Sourcee\n",
    "        \n",
    "        eles = driver.find_elements_by_xpath('//select[@name=\"ctl00$cphBody$cboState\"]')\n",
    "        r = requests.Session()\n",
    "        sesh1=r.get(site_url)\n",
    "        soup1 = BeautifulSoup(sesh1.content , \"lxml\")\n",
    "        states=[]\n",
    "        select = soup1.find('select', id=\"cphBody_cboState\")\n",
    "        for value in select.stripped_strings:\n",
    "            print (value)\n",
    "            states.append(value)\n",
    "        states = states[1:]  \n",
    "        states1 = ['Tamil Nadu','Kerala','Andhra Pradesh','Karnataka','Telangana','Pondycherry']\n",
    "        states = [elem for elem in states if elem in states1 ]\n",
    "        states = [st.strip() for st in states if((\"select\" not in st.lower()) & (st.strip()!=''))]#list of states\n",
    "        states = [states[0]]\n",
    "        main=pd.DataFrame()\n",
    "        all_dates = []\n",
    "        \n",
    "        # Giving a start date - Example is April of 2022\n",
    "        \n",
    "        st_mon = 4\n",
    "        st_year = 2022\n",
    "        \n",
    "        #list of dates loop\n",
    "        while True:\n",
    "            if((st_mon==today.month) & (st_year==today.year)):\n",
    "                break\n",
    "            if(st_mon==13):\n",
    "                st_mon = 1\n",
    "                st_year += 1\n",
    "            all_dates.append(datetime.date(st_year, st_mon, 1))\n",
    "            st_mon += 1\n",
    "        #All dates contains the dates from the start date above to todays date\n",
    "        \n",
    "        #For this example I am iterating through one State and one date\n",
    "        \n",
    "        for st in states:\n",
    "            print(st)\n",
    "            for date in [all_dates[0]]:\n",
    "                print(st, date)\n",
    "                \n",
    "                # Given a State and date we can pass it onto the function\n",
    "                driver = input_fun(driver, st, date)\n",
    "                # Implicit wait - important function to ensure the emulater waits till the JS element has loaded\n",
    "                driver.implicitly_wait(10)\n",
    "                xpath = '//*[@id=\"cphBody_Calendar1\"]/tbody//a'\n",
    "                eles = driver.find_elements_by_xpath(xpath)\n",
    "                all_text = []\n",
    "                for ele in eles:\n",
    "                    all_text.append(ele.text)\n",
    "                \n",
    "                # Starting a For Loop to iterate through the date - all_text[0] (Taking only 1 example)\n",
    "                for text in [all_text[0]]:\n",
    "                    code_rel_date = datetime.date(date.year, date.month, int(text))\n",
    "                    print(code_rel_date)\n",
    "                    driver = input_fun(driver, st, date)\n",
    "                    print(text)\n",
    "                    rel_date = date.strftime(\"%B %Y\")\n",
    "                    time.sleep(1)\n",
    "                    limit = 0\n",
    "                    #This While loop is to ensure the date is clicked by the bot and will be in loop 5 times before throwing an erro\n",
    "                    while True:\n",
    "                        try:\n",
    "                            cal = driver.find_elements_by_xpath('//*[@id=\"cphBody_Calendar1\"]/tbody/tr[1]/td/table/tbody//td')[0].text\n",
    "                            if(cal.strip()==rel_date):\n",
    "                                break\n",
    "                            else:\n",
    "                                raise Exception(\"Date Mismatch\")\n",
    "                        except:\n",
    "                            limit += 1\n",
    "                            if(limit>5):\n",
    "                                raise Exception(\"Internet slow\")\n",
    "                            time.sleep(2)\n",
    "                    ele = driver.find_elements_by_xpath(xpath + '[text() = \"' + text + '\"]')[0]\n",
    "                    ele.click()\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    #Clicking the Submit button to access data                    \n",
    "                    try:                        \n",
    "                        xpath_submit='//*[@id=\"cphBody_btnSubmit\"]'\n",
    "                        time.sleep(3)\n",
    "                        driver.implicitly_wait(10) # seconds\n",
    "                        submit = driver.find_element_by_xpath(xpath_submit)\n",
    "                        submit.click()\n",
    "                        driver.implicitly_wait(5)\n",
    "                    except NoSuchElementException:  \n",
    "                        runtime=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        continue                  \n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    '''\n",
    "                    Once the raw data is accessed we pass the browser to a clean up function\n",
    "                    to gather a clean dataframe\n",
    "                \n",
    "                    '''\n",
    "                    output=clean_up(driver,st)\n",
    "                    print(output.head())\n",
    "                    runtime=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "                    '''\n",
    "                    Going back to the website to go to the next date and/or state\n",
    "                    \n",
    "                    '''\n",
    "                    driver.get(site_url)\n",
    "        print(time.process_time() - start)\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        break\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "        main_limit += 1\n",
    "        if(main_limit>4):\n",
    "            error_msg = str(sys.exc_info()[1])\n",
    "            raise Exception(error_msg)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81027c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State           Market Arrivals_String  Arrivals  \\\n",
      "3   Andhra Pradesh             Alur            0.01      0.01   \n",
      "4   Andhra Pradesh    Banaganapalli               1      1.00   \n",
      "6   Andhra Pradesh          Atmakur            0.01      0.01   \n",
      "8   Andhra Pradesh          Atmakur            0.01      0.01   \n",
      "9   Andhra Pradesh    Banaganapalli               1      1.00   \n",
      "10  Andhra Pradesh      Rajahmundry               1      1.00   \n",
      "11  Andhra Pradesh              NaN             NaN       NaN   \n",
      "12  Andhra Pradesh           Tanuku               1      1.00   \n",
      "16  Andhra Pradesh       Ambajipeta              44     44.00   \n",
      "20  Andhra Pradesh         Cuddapah             1.2      1.20   \n",
      "24  Andhra Pradesh         Chittoor              45     45.00   \n",
      "25  Andhra Pradesh              NaN             NaN       NaN   \n",
      "26  Andhra Pradesh              NaN             NaN       NaN   \n",
      "30  Andhra Pradesh    Banaganapalli               1      1.00   \n",
      "31  Andhra Pradesh       Pattikonda               1      1.00   \n",
      "35  Andhra Pradesh           Guntur            3057   3057.00   \n",
      "36  Andhra Pradesh              NaN             NaN       NaN   \n",
      "37  Andhra Pradesh              NaN             NaN       NaN   \n",
      "41  Andhra Pradesh          Parchur               7      7.00   \n",
      "43  Andhra Pradesh          Parchur               1      1.00   \n",
      "45  Andhra Pradesh      Gopalavaram            23.2     23.20   \n",
      "46  Andhra Pradesh           Tenali             5.6      5.60   \n",
      "48  Andhra Pradesh       Pattikonda               1      1.00   \n",
      "50  Andhra Pradesh         Kalikiri           24.54     24.54   \n",
      "51  Andhra Pradesh  Mulakalacheruvu              86     86.00   \n",
      "52  Andhra Pradesh       Pattikonda             0.1      0.10   \n",
      "53  Andhra Pradesh       Vayalapadu           50.98     50.98   \n",
      "\n",
      "   Unit_of_Arrivals              Variety  Minimum_Prices  Maximum_Prices  \\\n",
      "3            Tonnes       Jowar ( White)            2400            2500   \n",
      "4            Tonnes       Jowar ( White)            1400            2000   \n",
      "6            Tonnes         Hybrid/Local            1850            1850   \n",
      "8            Tonnes         Sona Mahsuri            1800            1800   \n",
      "9            Tonnes         Sona Mahsuri            1800            2200   \n",
      "10           Tonnes                Paddy            1940            1940   \n",
      "11           Tonnes  Swarna Masuri (New)            1960            1960   \n",
      "12           Tonnes             MTU-1010            1960            1980   \n",
      "16           Tonnes        Banana - Ripe             920            1500   \n",
      "20           Tonnes                Local            5629            5629   \n",
      "24           Tonnes                 NO 1            4000            4000   \n",
      "25           Tonnes                 NO 2            3000            3300   \n",
      "26           Tonnes                 NO 3            2500            2500   \n",
      "30           Tonnes         Desi (Whole)            4500            4800   \n",
      "31           Tonnes         Jawari/Local            5000            5500   \n",
      "35           Tonnes                  Red            7000           20700   \n",
      "36           Tonnes              Red New            7000           20200   \n",
      "37           Tonnes                White            4000            9500   \n",
      "41           Tonnes               Bhindi            1000            1100   \n",
      "43           Tonnes         Green Chilly            2500            3000   \n",
      "45           Tonnes                Lemon            7500            8000   \n",
      "46           Tonnes                Lemon            9000           11300   \n",
      "48           Tonnes                Local            1000            2000   \n",
      "50           Tonnes                Local             500             750   \n",
      "51           Tonnes                Local             500             800   \n",
      "52           Tonnes                Local             800            1000   \n",
      "53           Tonnes                Local             600             880   \n",
      "\n",
      "    Modal_Prices Unit_of_Price Relevant_Date             Runtime Last_Updated  \n",
      "3           2450    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "4           1700    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "6           1850    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "8           1800    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "9           2000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "10          1940    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "11          1960    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "12          1970    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "16          1210    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "20          5629    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "24          4000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "25          3000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "26          2500    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "30          4650    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "31          5400    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "35         17000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "36         17000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "37          8500    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "41          1050    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "43          2750    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "45          7800    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "46         10000    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "48          1500    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "50           630    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "51           600    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "52           900    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n",
      "53           720    Rs/Quintal    2022-04-01 2024-10-15 00:13:45               \n"
     ]
    }
   ],
   "source": [
    "# VIEWING OUR DATASET\n",
    "print(output.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a752d",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Advantages \n",
    "- Selenium allows us to access difficult data corpuses which may not be accessed by Pythons BeautifulSoup or Scrapy\n",
    "- It can be used to navigate through Captchas\n",
    "- Helps emulate a human user to ensure legal compliance\n",
    "- Easy to deploy\n",
    "\n",
    "### Disadvantage\n",
    "- Very slow and time consuming when compared to Scrapy or BeautifulSoup\n",
    "- Difficult to debug when faced with errors\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
